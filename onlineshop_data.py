# -*- coding: utf-8 -*-
"""onlineShop_data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CKhV2_mJwUari0-XwmRoIMjRNSLddAqK
"""

import numpy as np
import pandas as pd
import kagglehub
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

# Download dataset
path = kagglehub.dataset_download("jacksondivakarr/online-shopping-dataset")
print("Path to dataset files:", path)

# Memuat dataset
df = pd.read_csv(f"{path}/file.csv")
print("Dataset berhasil dimuat")
print("Dimensi dataset:", df.shape)
print("\nSampel data:")
print(df.head())

# Memeriksa informasi dataset
print("\nInformasi dataset:")
print(df.info())

# Statistik deskriptif
print("\nStatistik deskriptif:")
print(df.describe())

# Memeriksa nilai yang hilang
print("\nNilai yang hilang:")
print(df.isnull().sum())

# Persiapan data untuk pemodelan
# Asumsikan kolom terakhir adalah target (semisal 'Category' atau 'Purchase')
# Sesuaikan dengan kolom target yang sebenarnya pada dataset
features = df.columns[:-1]  # Semua kolom kecuali yang terakhir
target = df.columns[-1]     # Kolom terakhir sebagai target

# Define the feature and target column names
Offline_Spend = 'Offline_Spend'  # Replace with the actual column name for Discount percentage
Delivery_Charges = 'Delivery_Charges'  # Replace with the actual column name for Coupon Status


print(f"\nFeatures yang digunakan: {Offline_Spend}")
print(f"Target yang diprediksi: {Delivery_Charges}")

# Pemisahan fitur dan target
X = df[[Offline_Spend]]
y = df[Delivery_Charges]

# Membagi data menjadi training dan testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.0015, random_state=13)
print("\nUkuran data training dan testing:")
print(f"X_train: {X_train.shape}, X_test: {X_test.shape}")
print(f"y_train: {y_train.shape}, y_test: {y_test.shape}")

# Standarisasi fitur
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Training model dengan Naive Bayes
print("\nTraining model dengan Naive Bayes...")
nvclassifier = GaussianNB()
# Drop rows with NaN in both feature and target variables from training data
X_train_scaled_cleaned = X_train_scaled[y_train.notna() & np.isfinite(X_train_scaled).all(axis=1)]
y_train_cleaned = y_train[y_train.notna() & np.isfinite(X_train_scaled).all(axis=1)]
# Convert target variable to categorical if necessary
# Assuming 'Online_Spend' represents categories, but currently is continuous
# You might need to adjust the binning strategy or use a different approach
# if 'Online_Spend' is truly continuous and you want to do regression
y_train_cleaned = pd.cut(y_train_cleaned, bins=10, labels=False) # Discretize into 10 bins
nvclassifier.fit(X_train_scaled_cleaned, y_train_cleaned)
print("Model berhasil dilatih")

# Prediksi dengan data testing
print("\nMelakukan prediksi pada data testing...")
# Replace NaN values with 0 in X_test_scaled
X_test_scaled = np.nan_to_num(X_test_scaled)
y_pred = nvclassifier.predict(X_test_scaled)
print("Hasil prediksi pada beberapa data:")
print(y_pred[:50])  # Tampilkan 10 prediksi pertama

# Membandingkan hasil prediksi dengan nilai sebenarnya
print("\nPerbandingan hasil prediksi dengan nilai sebenarnya:")
y_compare = np.vstack((y_test.values, y_pred)).T
y_compare_df = pd.DataFrame(y_compare, columns=['Aktual', 'Prediksi'])
print(y_compare_df.head(50))

# Evaluasi model
print("\nEvaluasi model:")
# Convert y_test to discrete values to match y_pred
y_test_discrete = pd.cut(y_test, bins=10, labels=False)
# Confusion Matrix
cm = confusion_matrix(y_test_discrete, y_pred) # Use discretized y_test
print("Confusion Matrix:")
print(cm)

# Accuracy
accuracy = accuracy_score(y_test_discrete, y_pred) # Use discretized y_test
print(f"Accuracy: {accuracy:.4f}")

# Classification Report
print("\nClassification Report:")
print(classification_report(y_test_discrete, y_pred)) # Use discretized y_test

# Uji prediksi dengan sampel baru
print("\nUji prediksi dengan sampel dari data testing:")
sample_indices = np.random.randint(0, len(X_test), 5)
samples = X_test_scaled[sample_indices]
sample_predictions = nvclassifier.predict(samples)
sample_actuals = y_test.iloc[sample_indices].values

print("Sampel data dan prediksinya:")
for i, (pred, actual) in enumerate(zip(sample_predictions, sample_actuals)):
    print(f"Sampel {i+1}: Prediksi = {pred}, Aktual = {actual}")